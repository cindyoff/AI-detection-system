# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZunjSGo9OJ_8EP1ZeZt6598Dnooj9zLR
"""

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

!pip install pyspellchecker
!pip install tensorflow

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from scipy.sparse import hstack, csr_matrix
import re
import string
from collections import Counter
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.metrics import auc

# Charger les datasets
df = pd.read_csv('train.csv')
test = pd.read_csv('article_level_data_new.csv', sep=';')

df.rename(columns={'Generation':'article'}, inplace=True)
df.rename(columns={'label':'class'}, inplace=True)

# Recoder les labels
df['binary_label'] = df['class'].apply(lambda x: 1 if 'human' in x else 0)
test['binary_label'] = test['class'].apply(lambda x: 1 if x == 1 else 0)

# Mélanger la base test avant de diviser
test_shuffled = test.sample(frac=1, random_state=42).reset_index(drop=True)  # Mélanger test

# Diviser test en 2 parties : une pour l'entraînement et l'autre pour le test
test_split_index = int(len(test_shuffled) * 0.3)
test_part_train = test_shuffled[:test_split_index]  # Partie de test à ajouter à l'entraînement
test_part_test = test_shuffled[test_split_index:]  # Partie restante de test pour l'évaluation

# Ajouter la partie de test à df pour l'entraînement
df_with_test = pd.concat([df, test_part_train], ignore_index=True)

# Création Features
def count_repeated_words(text):
    word_counts = Counter(text.split())
    return sum(count > 2 for count in word_counts.values())

def punctuation_ratio(text):
    punctuation_count = sum(1 for char in text if char in string.punctuation)
    return punctuation_count / len(text) if len(text) > 0 else 0

def sentence_length_variance(text):
    sentences = text.split('.')
    lengths = [len(sentence.split()) for sentence in sentences if len(sentence) > 0]
    return np.var(lengths) if lengths else 0

def detect_human_markers(text):
    human_markers = {"i", "me", "my", "mine", "myself"}
    return sum(1 for word in text.split() if word in human_markers)

def count_informal_words(text):
    informal_words = {"idk", "btw", "u", "gonna", "lemme", "wanna", "y’all", "gimme", "dunno", "lol"}
    return sum(1 for word in text.split() if word in informal_words)

def detect_emotional_tone(text):
    emotion_words = {"love", "hate", "happy", "sad", "excited", "angry", "surprised", "disappointed"}
    return sum(1 for word in text.split() if word in emotion_words)

def count_punctuation_issues(text):
    return len(re.findall(r'[!?.,]{2,}', text))

def count_hyphen_splits(text):
    return len(re.findall(r'\w+-\s', text))

def count_abnormal_spaces(text):
    return len(re.findall(r'\s{2,}|(?<!\s)\s(?!\s)', text))

def add_features(df):
    df['text_length'] = df['article'].astype(str).apply(lambda x: len(x.split()))
    df['repeated_words'] = df['article'].astype(str).apply(count_repeated_words)
    df['punctuation_ratio'] = df['article'].astype(str).apply(punctuation_ratio)
    df['sentence_length_var'] = df['article'].astype(str).apply(sentence_length_variance)
    df['human_markers'] = df['article'].astype(str).apply(detect_human_markers)
    df['informal_words'] = df['article'].astype(str).apply(count_informal_words)
    df['emotional_tone'] = df['article'].astype(str).apply(detect_emotional_tone)
    df['punctuation_issues'] = df['article'].astype(str).apply(count_punctuation_issues)
    df['hyphen_splits'] = df['article'].astype(str).apply(count_hyphen_splits)
    df['abnormal_spaces'] = df['article'].astype(str).apply(count_abnormal_spaces)
    return df

df_with_test = add_features(df_with_test)
test_part_test = add_features(test_part_test)

# Séparation en ensemble d'entraînement et de test
X_train = df_with_test.drop(columns=['class', 'binary_label'])
y_train = df_with_test['binary_label']
X_test = test_part_test.drop(columns=['class', 'binary_label'])
y_test = test_part_test['binary_label']

# Vectorisation TF-IDF
vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = vectorizer.fit_transform(X_train['article'].astype(str))
X_test_tfidf = vectorizer.transform(X_test['article'].astype(str))

# Concaténer les features manuelles et TF-IDF
X_train_manual = csr_matrix(X_train.drop(columns=['article']).values.astype(np.float64))
X_test_manual = csr_matrix(X_test.drop(columns=['article']).values.astype(np.float64))
X_train_full = hstack([X_train_tfidf, X_train_manual])
X_test_full = hstack([X_test_tfidf, X_test_manual])

# Appliquer SMOTE seulement si les deux classes sont présentes
if len(y_train.unique()) > 1:
    sm = SMOTE(random_state=42)
    X_train_balanced, y_train_balanced = sm.fit_resample(X_train_full, y_train)
else:
    X_train_balanced, y_train_balanced = X_train_full, y_train

# Entraînement du modèle
clf = XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=6, scale_pos_weight=1.5, random_state=42)
clf.fit(X_train_balanced, y_train_balanced)

# Prédiction et évaluation sur la partie restante de la base test
y_pred = clf.predict(X_test_full)
print('Classification Report:')
print(classification_report(y_test, y_pred))

# Matrice de confusion
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Prédictions')
plt.ylabel('Vraies valeurs')
plt.title('Matrice de Confusion')
plt.show()

# Importance des features manuelles
feature_importance = clf.feature_importances_[-X_train_manual.shape[1]:]
feature_names = X_train.drop(columns=['article']).columns

plt.figure(figsize=(10, 6))
sns.barplot(x=feature_importance, y=feature_names)
plt.title("Importance des Features Manuelles")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.show()

# courbe ROC et AUC
y_proba = clf.predict_proba(X_test_full)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='Courbe ROC (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taux de Faux Positifs')
plt.ylabel('Taux de Vrais Positifs')
plt.title('Courbe ROC - Modèle XGBoost')
plt.legend(loc="lower right")
plt.show()

print(f"Aire sous la courbe ROC (AUC): {roc_auc:.4f}")